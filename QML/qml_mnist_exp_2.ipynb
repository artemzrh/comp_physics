{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrVqtWl6mL-M"
      },
      "outputs": [],
      "source": [
        "#!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Fixed Quantum MNIST (binarized): QNN, QCNN, HQNN\n",
        "\n",
        "- Data from: qml.data.load(\"other\", name=\"binarized-mnist\")\n",
        "- 50'000 train, 10'000 test, each input: bitstring of length 784\n",
        "\n",
        "Design:\n",
        "- QNN: 10 qubits, 4 layers, stronger downscale MLP\n",
        "- QCNN: 8 qubits, 2 conv+pool levels, 4 quantum outputs, larger classical head\n",
        "- HQNN: 8-qubit 3-layer quantum core + CNN + dropout, own small QNode\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import pennylane as qml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# Global config\n",
        "# ----------------------------\n",
        "n_classes = 10\n",
        "\n",
        "# QNN config\n",
        "n_qubits_qnn = 10\n",
        "n_layers_qnn = 4\n",
        "\n",
        "# QCNN + HQNN config\n",
        "n_qubits_small = 8\n",
        "n_layers_small = 3\n",
        "\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "lr = 1e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# choose \"qnn\", \"qcnn\", or \"hqnn\"\n",
        "MODEL_CHOICE = \"hqnn\""
      ],
      "metadata": {
        "id": "0K9BG50opEOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 1. Load binarized MNIST via qml.data\n",
        "# ----------------------------\n",
        "print(\"Loading binarized MNIST from PennyLane...\")\n",
        "[ds] = qml.data.load(\"other\", name=\"binarized-mnist\")\n",
        "\n",
        "x_train = torch.tensor(ds.train[\"inputs\"], dtype=torch.float32)  # (50000, 784)\n",
        "y_train = torch.tensor(ds.train[\"labels\"], dtype=torch.long)    # (50000,)\n",
        "\n",
        "x_test = torch.tensor(ds.test[\"inputs\"], dtype=torch.float32)   # (10000, 784)\n",
        "y_test = torch.tensor(ds.test[\"labels\"], dtype=torch.long)      # (10000,)\n",
        "\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset  = TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Hd-h_SipJfS",
        "outputId": "6e29ec6e-4f34-4ee6-ac3a-a1aa63ae21ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading binarized MNIST from PennyLane...\n",
            "Train shape: torch.Size([50000, 784]), Test shape: torch.Size([10000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 2. Classical helper modules\n",
        "# ----------------------------\n",
        "class BetterDownscale(nn.Module):\n",
        "    \"\"\"\n",
        "    Improved downscale network:\n",
        "    - Reshape 784 -> (1, 28, 28)\n",
        "    - AvgPool to 7x7\n",
        "    - MLP: 49 -> hidden -> n_qubits\n",
        "\n",
        "    Used by QNN and QCNN (with different n_qubits).\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qubits, hidden=64):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "        self.fc1 = nn.Linear(7 * 7, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, n_qubits)\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 784)\n",
        "        x = x.view(x.size(0), 1, 28, 28)   # -> (B,1,28,28)\n",
        "        x = self.pool(x)                   # -> (B,1,7,7)\n",
        "        x = x.view(x.size(0), -1)          # -> (B,49)\n",
        "        x = self.act(self.fc1(x))          # -> (B,hidden)\n",
        "        x = self.fc2(x)                    # -> (B,n_qubits)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Small classical CNN for HQNN feature extraction.\n",
        "    Also expects flat 784 inputs and reshapes inside.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # 28x28 -> 14x14\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # 14x14 -> 7x7\n",
        "        )\n",
        "        self.fc = nn.Linear(32 * 7 * 7, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 784)\n",
        "        x = x.view(x.size(0), 1, 28, 28)  # -> (B,1,28,28)\n",
        "        x = self.conv(x)                  # -> (B,32,7,7)\n",
        "        x = x.view(x.size(0), -1)         # -> (B,32*7*7)\n",
        "        return self.fc(x)                 # -> (B, latent_dim)"
      ],
      "metadata": {
        "id": "k7H1k_3dpL92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 3. Devices\n",
        "# ----------------------------\n",
        "# QNN uses its own (larger) device\n",
        "dev_qnn = qml.device(\"default.qubit\", wires=n_qubits_qnn)\n",
        "\n",
        "# QCNN + HQNN share a smaller 8-qubit device\n",
        "dev_small = qml.device(\"default.qubit\", wires=n_qubits_small)"
      ],
      "metadata": {
        "id": "VA82YYs3pOFu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 4. QNN circuit (10 qubits, 4 layers)\n",
        "# ----------------------------\n",
        "@qml.qnode(dev_qnn, interface=\"torch\")\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    Quantum circuit for the standalone QNN:\n",
        "    - AngleEmbedding of n_qubits_qnn features\n",
        "    - StronglyEntanglingLayers with trainable parameters\n",
        "    - returns <Z> on each qubit (length n_qubits_qnn)\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits_qnn), rotation=\"Y\")\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits_qnn))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits_qnn)]\n",
        "\n",
        "qnn_shapes = {\"weights\": (n_layers_qnn, n_qubits_qnn, 3)}\n",
        "QNNLayerBig = qml.qnn.TorchLayer(qnn_circuit, qnn_shapes)"
      ],
      "metadata": {
        "id": "AtKG4olfpPcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 5. HQNN circuit (8 qubits, 3 layers)\n",
        "# ----------------------------\n",
        "@qml.qnode(dev_small, interface=\"torch\")\n",
        "def hqnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    Quantum circuit used inside the HQNN:\n",
        "    - 8 qubits, 3 layers (baseline size)\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits_small), rotation=\"Y\")\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits_small))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits_small)]\n",
        "\n",
        "hqnn_shapes = {\"weights\": (n_layers_small, n_qubits_small, 3)}\n",
        "QNNLayerSmall = qml.qnn.TorchLayer(hqnn_circuit, hqnn_shapes)"
      ],
      "metadata": {
        "id": "gCOoQ5EFpREJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 6. QCNN circuit (8 qubits, 4 outputs)\n",
        "# ----------------------------\n",
        "def conv_block(params, wires):\n",
        "    \"\"\"\n",
        "    Quantum \"convolution\" on two qubits (small device: 8 qubits).\n",
        "    \"\"\"\n",
        "    i, j = wires\n",
        "    qml.CNOT([i, j])\n",
        "    qml.RY(params[0], i)\n",
        "    qml.RY(params[1], j)\n",
        "    qml.RZ(params[2], j)\n",
        "    qml.CNOT([i, j])\n",
        "\n",
        "def pooling_block(params, wires):\n",
        "    \"\"\"\n",
        "    Quantum \"pooling\" on two qubits: keep i, pool/discard j.\n",
        "    \"\"\"\n",
        "    i, j = wires\n",
        "    qml.CNOT([i, j])\n",
        "    qml.RY(params[0], i)\n",
        "    qml.RZ(params[1], i)\n",
        "\n",
        "@qml.qnode(dev_small, interface=\"torch\")\n",
        "def qcnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    QCNN-style circuit on 8 qubits:\n",
        "    - AngleEmbedding on all 8 qubits\n",
        "    - conv+pool on pairs (0,1),(2,3),(4,5),(6,7)\n",
        "    - conv+pool on pairs (0,2),(4,6)\n",
        "    - measure 4 qubits: 0, 2, 4, 6 (4 outputs)\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits_small), rotation=\"Y\")\n",
        "\n",
        "    w = weights.reshape(-1)\n",
        "    idx = 0\n",
        "\n",
        "    conv1 = [(0, 1), (2, 3), (4, 5), (6, 7)]\n",
        "    for p in conv1:\n",
        "        conv_block(w[idx:idx+3], p)\n",
        "        idx += 3\n",
        "\n",
        "    for p in conv1:\n",
        "        pooling_block(w[idx:idx+2], p)\n",
        "        idx += 2\n",
        "\n",
        "    conv2 = [(0, 2), (4, 6)]\n",
        "    for p in conv2:\n",
        "        conv_block(w[idx:idx+3], p)\n",
        "        idx += 3\n",
        "\n",
        "    for p in conv2:\n",
        "        pooling_block(w[idx:idx+2], p)\n",
        "        idx += 2\n",
        "\n",
        "    return [\n",
        "        qml.expval(qml.PauliZ(0)),\n",
        "        qml.expval(qml.PauliZ(2)),\n",
        "        qml.expval(qml.PauliZ(4)),\n",
        "        qml.expval(qml.PauliZ(6)),\n",
        "    ]\n",
        "\n",
        "qcnn_shapes = {\"weights\": (30,)}\n",
        "QCNNLayer = qml.qnn.TorchLayer(qcnn_circuit, qcnn_shapes)"
      ],
      "metadata": {
        "id": "DmfYhUEDpSsp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 7. Models: QNN, QCNN, HQNN\n",
        "# ----------------------------\n",
        "class QNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    QNN:\n",
        "    bitstring (784) -> BetterDownscale(10) -> QNNLayerBig -> Linear(10->10)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre = BetterDownscale(n_qubits_qnn)\n",
        "        self.q = QNNLayerBig\n",
        "        self.fc = nn.Linear(n_qubits_qnn, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre(x)              # (B, n_qubits_qnn)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.q(x)                # (B, n_qubits_qnn)\n",
        "        return self.fc(x)            # (B, 10)\n",
        "\n",
        "\n",
        "class QCNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    QCNN:\n",
        "    bitstring (784) -> BetterDownscale(8) -> QCNNLayer -> MLP head (4->32->10)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre = BetterDownscale(n_qubits_small)\n",
        "        self.q = QCNNLayer\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(4, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, n_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre(x)              # (B, n_qubits_small)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.q(x)                # (B, 4)\n",
        "        return self.fc(x)            # (B, 10)\n",
        "\n",
        "\n",
        "class HQNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    HQNN (hybrid):\n",
        "    bitstring (784) -> SmallCNN -> Linear(latent->8)\n",
        "                      -> Dropout -> QNNLayerSmall -> Linear(8->10)\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=32, p_dropout=0.3):\n",
        "        super().__init__()\n",
        "        self.cnn = SmallCNN(latent_dim)\n",
        "        self.to_q = nn.Linear(latent_dim, n_qubits_small)\n",
        "        self.dropout = nn.Dropout(p_dropout)\n",
        "        self.q = QNNLayerSmall\n",
        "        self.fc = nn.Linear(n_qubits_small, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.cnn(x)              # (B, latent_dim)\n",
        "        z = self.to_q(z)             # (B, n_qubits_small)\n",
        "        z = self.dropout(z)\n",
        "        z = torch.tanh(z)\n",
        "        z = self.q(z)                # (B, n_qubits_small)\n",
        "        return self.fc(z)            # (B, 10)"
      ],
      "metadata": {
        "id": "XwcRGTRYpUwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 8. Plotting metrics\n",
        "# ----------------------------\n",
        "def plot_metrics(history, model_name):\n",
        "    epochs_list = history[\"epoch\"]\n",
        "    train_loss = history[\"train_loss\"]\n",
        "    test_loss  = history[\"test_loss\"]\n",
        "    train_acc  = history[\"train_acc\"]\n",
        "    test_acc   = history[\"test_acc\"]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axs[0].plot(epochs_list, train_loss, label=\"Train loss\")\n",
        "    axs[0].plot(epochs_list, test_loss,  label=\"Test loss\")\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Loss\")\n",
        "    axs[0].set_title(\"Loss\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].plot(epochs_list, train_acc, label=\"Train acc\")\n",
        "    axs[1].plot(epochs_list, test_acc,  label=\"Test acc\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].set_title(\"Accuracy\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    out_name = f\"{model_name}_metrics.png\"\n",
        "    plt.savefig(out_name, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\"Saved metrics plot to {out_name}\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "xNy8DhhnpWij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 9. Confusion matrix utilities\n",
        "# ----------------------------\n",
        "def compute_confusion_matrix(y_true, y_pred, num_classes):\n",
        "    cm = torch.zeros(num_classes, num_classes, dtype=torch.int64)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        cm[t, p] += 1\n",
        "    return cm\n",
        "\n",
        "def plot_confusion_matrix(cm, model_name):\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    im = ax.imshow(cm.numpy(), interpolation=\"nearest\")\n",
        "    ax.figure.colorbar(im, ax=ax)\n",
        "    ax.set_title(f\"Confusion Matrix ({model_name.upper()})\")\n",
        "    ax.set_xlabel(\"Predicted label\")\n",
        "    ax.set_ylabel(\"True label\")\n",
        "\n",
        "    tick_marks = range(n_classes)\n",
        "    ax.set_xticks(tick_marks)\n",
        "    ax.set_yticks(tick_marks)\n",
        "    ax.set_xticklabels(tick_marks)\n",
        "    ax.set_yticklabels(tick_marks)\n",
        "\n",
        "    thresh = cm.max().item() / 2.0 if cm.max().item() > 0 else 0.5\n",
        "    for i in range(n_classes):\n",
        "        for j in range(n_classes):\n",
        "            value = cm[i, j].item()\n",
        "            ax.text(\n",
        "                j, i, str(value),\n",
        "                ha=\"center\", va=\"center\",\n",
        "                color=\"white\" if value > thresh else \"black\",\n",
        "                fontsize=8,\n",
        "            )\n",
        "\n",
        "    plt.tight_layout()\n",
        "    out_name = f\"{model_name}_confusion.png\"\n",
        "    plt.savefig(out_name, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\"Saved confusion matrix to {out_name}\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "sqWDj1MmpYTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 10. Circuit figures\n",
        "# ----------------------------\n",
        "def save_circuit_figures():\n",
        "    \"\"\"\n",
        "    Save circuit diagrams for:\n",
        "    - QNN (10-qubit circuit)\n",
        "    - HQNN quantum subcircuit (8-qubit)\n",
        "    - QCNN (8-qubit QCNN)\n",
        "    \"\"\"\n",
        "    # QNN\n",
        "    fq = torch.zeros(n_qubits_qnn)\n",
        "    wq = torch.zeros(n_layers_qnn, n_qubits_qnn, 3)\n",
        "    fig1, ax1 = qml.draw_mpl(qnn_circuit)(fq, wq)\n",
        "    fig1.savefig(\"qnn_circuit.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"Saved QNN circuit figure to qnn_circuit.png\")\n",
        "    plt.close(fig1)\n",
        "\n",
        "    # HQNN quantum subcircuit\n",
        "    fh = torch.zeros(n_qubits_small)\n",
        "    wh = torch.zeros(n_layers_small, n_qubits_small, 3)\n",
        "    fig2, ax2 = qml.draw_mpl(hqnn_circuit)(fh, wh)\n",
        "    fig2.savefig(\"hqnn_circuit.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"Saved HQNN circuit figure to hqnn_circuit.png\")\n",
        "    plt.close(fig2)\n",
        "\n",
        "    # QCNN\n",
        "    fqc = torch.zeros(n_qubits_small)\n",
        "    wqc = torch.zeros(30)\n",
        "    fig3, ax3 = qml.draw_mpl(qcnn_circuit)(fqc, wqc)\n",
        "    fig3.savefig(\"qcnn_circuit.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"Saved QCNN circuit figure to qcnn_circuit.png\")\n",
        "    plt.close(fig3)"
      ],
      "metadata": {
        "id": "qWM7FuWxpZz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 11. Results table\n",
        "# ----------------------------\n",
        "def print_results_table(history, model, model_name):\n",
        "    final_train_loss = history[\"train_loss\"][-1]\n",
        "    final_test_loss  = history[\"test_loss\"][-1]\n",
        "    final_train_acc  = history[\"train_acc\"][-1]\n",
        "    final_test_acc   = history[\"test_acc\"][-1]\n",
        "    n_params = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    print(\"\\n=== Results Summary ===\")\n",
        "    print(f\"Model: {model_name.upper()}\")\n",
        "    print(f\"Parameters: {n_params}\")\n",
        "    print(\"----------------------------\")\n",
        "    print(\"Metric        | Value\")\n",
        "    print(\"----------------------------\")\n",
        "    print(f\"Train loss    | {final_train_loss:.4f}\")\n",
        "    print(f\"Test loss     | {final_test_loss:.4f}\")\n",
        "    print(f\"Train acc     | {final_train_acc:.4f}\")\n",
        "    print(f\"Test acc      | {final_test_acc:.4f}\")\n",
        "    print(\"----------------------------\\n\")\n",
        "\n",
        "    print(\"Markdown row for table:\")\n",
        "    print(\n",
        "        f\"| {model_name.upper()} | {n_params} | \"\n",
        "        f\"{final_train_acc:.4f} | {final_test_acc:.4f} | \"\n",
        "        f\"{final_train_loss:.4f} | {final_test_loss:.4f} |\"\n",
        "    )\n",
        "    print()"
      ],
      "metadata": {
        "id": "rJ_o-AEQpbYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 12. Training / evaluation\n",
        "# ----------------------------\n",
        "def train_and_evaluate(model, model_name):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {\n",
        "        \"epoch\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "    }\n",
        "\n",
        "    last_y_true = None\n",
        "    last_y_pred = None\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            total_correct += (preds == yb).sum().item()\n",
        "            total_samples += yb.size(0)\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "        train_acc = total_correct / total_samples\n",
        "\n",
        "        # ---- test ----\n",
        "        model.eval()\n",
        "        test_loss_total = 0.0\n",
        "        test_correct = 0\n",
        "        test_samples = 0\n",
        "        all_y_true = []\n",
        "        all_y_pred = []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = loss_fn(logits, yb)\n",
        "                test_loss_total += loss.item() * xb.size(0)\n",
        "                preds = logits.argmax(1)\n",
        "                test_correct += (preds == yb).sum().item()\n",
        "                test_samples += yb.size(0)\n",
        "\n",
        "                all_y_true.append(yb.cpu())\n",
        "                all_y_pred.append(preds.cpu())\n",
        "\n",
        "        test_loss = test_loss_total / test_samples\n",
        "        test_acc = test_correct / test_samples\n",
        "\n",
        "        history[\"epoch\"].append(ep)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_loss\"].append(test_loss)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        last_y_true = torch.cat(all_y_true, dim=0)\n",
        "        last_y_pred = torch.cat(all_y_pred, dim=0)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {ep:02d} | \"\n",
        "            f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
        "            f\"Test loss: {test_loss:.4f}, acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "    plot_metrics(history, model_name)\n",
        "    return history, last_y_true, last_y_pred"
      ],
      "metadata": {
        "id": "alOYDkKQpc6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 13. Main\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"Training model: {MODEL_CHOICE.upper()} on binarized MNIST\")\n",
        "\n",
        "    if MODEL_CHOICE.lower() == \"qnn\":\n",
        "        model = QNNModel()\n",
        "        name = \"qnn\"\n",
        "    elif MODEL_CHOICE.lower() == \"qcnn\":\n",
        "        model = QCNNModel()\n",
        "        name = \"qcnn\"\n",
        "    elif MODEL_CHOICE.lower() == \"hqnn\":\n",
        "        model = HQNNModel()\n",
        "        name = \"hqnn\"\n",
        "    else:\n",
        "        raise ValueError(\"MODEL_CHOICE must be 'qnn', 'qcnn', or 'hqnn'.\")\n",
        "\n",
        "    history, y_true, y_pred = train_and_evaluate(model, name)\n",
        "\n",
        "    cm = compute_confusion_matrix(y_true, y_pred, n_classes)\n",
        "    plot_confusion_matrix(cm, name)\n",
        "\n",
        "    print_results_table(history, model, name)\n",
        "\n",
        "    save_circuit_figures()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElITdDj0pfDn",
        "outputId": "9a38b007-5daf-4602-b868-30dc5b14a61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Training model: HQNN on binarized MNIST\n",
            "Epoch 01 | Train loss: 2.0593, acc: 0.3962 | Test loss: 1.3881, acc: 0.5970\n",
            "Epoch 02 | Train loss: 1.4362, acc: 0.5010 | Test loss: 0.8346, acc: 0.7150\n",
            "Epoch 03 | Train loss: 1.1964, acc: 0.5699 | Test loss: 0.7073, acc: 0.7056\n",
            "Epoch 04 | Train loss: 1.0865, acc: 0.6230 | Test loss: 0.6058, acc: 0.8527\n",
            "Epoch 05 | Train loss: 0.9841, acc: 0.6915 | Test loss: 0.5079, acc: 0.8684\n",
            "Epoch 06 | Train loss: 0.8928, acc: 0.7219 | Test loss: 0.4325, acc: 0.8732\n",
            "Epoch 07 | Train loss: 0.8058, acc: 0.7516 | Test loss: 0.3655, acc: 0.8775\n",
            "Epoch 08 | Train loss: 0.7468, acc: 0.7726 | Test loss: 0.3280, acc: 0.8812\n",
            "Epoch 09 | Train loss: 0.7008, acc: 0.7837 | Test loss: 0.3100, acc: 0.9018\n",
            "Epoch 10 | Train loss: 0.6627, acc: 0.7988 | Test loss: 0.2978, acc: 0.8927\n",
            "Epoch 11 | Train loss: 0.6201, acc: 0.8164 | Test loss: 0.2654, acc: 0.9486\n",
            "Epoch 12 | Train loss: 0.5761, acc: 0.8372 | Test loss: 0.2354, acc: 0.9665\n",
            "Epoch 13 | Train loss: 0.5429, acc: 0.8486 | Test loss: 0.1970, acc: 0.9716\n",
            "Epoch 14 | Train loss: 0.5055, acc: 0.8571 | Test loss: 0.1787, acc: 0.9692\n",
            "Epoch 15 | Train loss: 0.4731, acc: 0.8623 | Test loss: 0.1476, acc: 0.9754\n",
            "Epoch 16 | Train loss: 0.4464, acc: 0.8683 | Test loss: 0.1360, acc: 0.9772\n",
            "Epoch 17 | Train loss: 0.4307, acc: 0.8681 | Test loss: 0.1228, acc: 0.9783\n",
            "Epoch 18 | Train loss: 0.4147, acc: 0.8705 | Test loss: 0.1175, acc: 0.9772\n",
            "Epoch 19 | Train loss: 0.4001, acc: 0.8745 | Test loss: 0.1157, acc: 0.9758\n",
            "Epoch 20 | Train loss: 0.3813, acc: 0.8785 | Test loss: 0.1132, acc: 0.9765\n",
            "Saved metrics plot to hqnn_metrics.png\n",
            "Saved confusion matrix to hqnn_confusion.png\n",
            "\n",
            "=== Results Summary ===\n",
            "Model: HQNN\n",
            "Parameters: 55434\n",
            "----------------------------\n",
            "Metric        | Value\n",
            "----------------------------\n",
            "Train loss    | 0.3813\n",
            "Test loss     | 0.1132\n",
            "Train acc     | 0.8785\n",
            "Test acc      | 0.9765\n",
            "----------------------------\n",
            "\n",
            "Markdown row for table:\n",
            "| HQNN | 55434 | 0.8785 | 0.9765 | 0.3813 | 0.1132 |\n",
            "\n",
            "Saved QNN circuit figure to qnn_circuit.png\n",
            "Saved HQNN circuit figure to hqnn_circuit.png\n",
            "Saved QCNN circuit figure to qcnn_circuit.png\n"
          ]
        }
      ]
    }
  ]
}