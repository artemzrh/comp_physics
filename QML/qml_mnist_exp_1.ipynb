{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwkAAtvFXgUt"
      },
      "outputs": [],
      "source": [
        "#!pip install pennylane"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Quantum MNIST (binarized): QNN, QCNN, HQNN\n",
        "\n",
        "- Data from: qml.data.load(\"other\", name=\"binarized-mnist\")\n",
        "- 50'000 train, 10'000 test, each input: bitstring of length 784\n",
        "\n",
        "Features:\n",
        "- Performance logging (loss + accuracy)\n",
        "- Metric plots per model: <model_name>_metrics.png\n",
        "- Circuit figures: qnn_circuit.png, qcnn_circuit.png\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import TensorDataset\n",
        "import pennylane as qml\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "n_qubits = 8\n",
        "n_classes = 10\n",
        "n_layers = 3\n",
        "batch_size = 128\n",
        "epochs = 20\n",
        "lr = 1e-3\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# choose \"qnn\", \"qcnn\", or \"hqnn\"\n",
        "MODEL_CHOICE = \"hqnn\""
      ],
      "metadata": {
        "id": "UT9QnoRDXkoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 1. Load binarized MNIST via qml.data\n",
        "# ----------------------------\n",
        "print(\"Loading binarized MNIST from PennyLane...\")\n",
        "[ds] = qml.data.load(\"other\", name=\"binarized-mnist\")\n",
        "\n",
        "# ds.train[\"inputs\"]: (50000, 784) array of 0/1\n",
        "# ds.train[\"labels\"]: (50000,) array of digits 0–9\n",
        "x_train = torch.tensor(ds.train[\"inputs\"], dtype=torch.float32)\n",
        "y_train = torch.tensor(ds.train[\"labels\"], dtype=torch.long)\n",
        "\n",
        "x_test = torch.tensor(ds.test[\"inputs\"], dtype=torch.float32)\n",
        "y_test = torch.tensor(ds.test[\"labels\"], dtype=torch.long)\n",
        "\n",
        "# Create PyTorch datasets/loaders\n",
        "train_dataset = TensorDataset(x_train, y_train)\n",
        "test_dataset  = TensorDataset(x_test, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train shape: {x_train.shape}, Test shape: {x_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhkpoSKQXpwa",
        "outputId": "8c613e7b-50e2-4b7d-ea47-694df154d871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading binarized MNIST from PennyLane...\n",
            "Train shape: torch.Size([50000, 784]), Test shape: torch.Size([10000, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 2. Classical helper modules\n",
        "# ----------------------------\n",
        "class SimpleDownscale(nn.Module):\n",
        "    \"\"\"\n",
        "    Downscale 28x28 -> 4x4 via avg pooling, then 16 -> n_qubits via linear layer.\n",
        "\n",
        "    Here the model receives inputs as flat vectors of length 784.\n",
        "    Inside forward() we reshape to (B,1,28,28) and then pool.\n",
        "    Used by QNN and QCNN.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_qubits):\n",
        "        super().__init__()\n",
        "        self.pool = nn.AdaptiveAvgPool2d((4, 4))\n",
        "        self.fc = nn.Linear(16, n_qubits)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, 784) bitstrings\n",
        "        x = x.view(x.size(0), 1, 28, 28)   # -> (B,1,28,28)\n",
        "        x = self.pool(x)                   # -> (B,1,4,4)\n",
        "        x = x.view(x.size(0), -1)          # -> (B,16)\n",
        "        x = self.fc(x)                     # -> (B,n_qubits)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SmallCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Small classical CNN for HQNN feature extraction.\n",
        "    Also expects flat 784 inputs and reshapes inside.\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # 28x28 -> 14x14\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),      # 14x14 -> 7x7\n",
        "        )\n",
        "        self.fc = nn.Linear(32 * 7 * 7, latent_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 784)\n",
        "        x = x.view(x.size(0), 1, 28, 28)  # -> (B,1,28,28)\n",
        "        x = self.conv(x)                  # -> (B,32,7,7)\n",
        "        x = x.view(x.size(0), -1)         # -> (B,32*7*7)\n",
        "        return self.fc(x)                 # -> (B, latent_dim)"
      ],
      "metadata": {
        "id": "afYQXGA0YCO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 3. PennyLane device\n",
        "# ----------------------------\n",
        "dev = qml.device(\"default.qubit\", wires=n_qubits)"
      ],
      "metadata": {
        "id": "yQZUnsACcYy4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 4. QNN circuit (AngleEmbedding + variational ansatz)\n",
        "# ----------------------------\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def qnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    Quantum circuit for QNN and HQNN:\n",
        "    - AngleEmbedding of n_qubits features\n",
        "    - StronglyEntanglingLayers with trainable parameters\n",
        "    - returns <Z> on each qubit (length n_qubits)\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")\n",
        "    qml.StronglyEntanglingLayers(weights, wires=range(n_qubits))\n",
        "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
        "\n",
        "qnn_shapes = {\"weights\": (n_layers, n_qubits, 3)}\n",
        "QNNLayer = qml.qnn.TorchLayer(qnn_circuit, qnn_shapes)"
      ],
      "metadata": {
        "id": "0dYd7yxgcZMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 5. QCNN circuit blocks & circuit\n",
        "# ----------------------------\n",
        "def conv_block(params, wires):\n",
        "    \"\"\"\n",
        "    Quantum \"convolution\" on two qubits.\n",
        "    \"\"\"\n",
        "    i, j = wires\n",
        "    qml.CNOT([i, j])\n",
        "    qml.RY(params[0], i)\n",
        "    qml.RY(params[1], j)\n",
        "    qml.RZ(params[2], j)\n",
        "    qml.CNOT([i, j])\n",
        "\n",
        "def pooling_block(params, wires):\n",
        "    \"\"\"\n",
        "    Quantum \"pooling\" on two qubits: keep i, pool/discard j.\n",
        "    \"\"\"\n",
        "    i, j = wires\n",
        "    qml.CNOT([i, j])\n",
        "    qml.RY(params[0], i)\n",
        "    qml.RZ(params[1], i)\n",
        "\n",
        "@qml.qnode(dev, interface=\"torch\")\n",
        "def qcnn_circuit(inputs, weights):\n",
        "    \"\"\"\n",
        "    QCNN-style circuit:\n",
        "    - AngleEmbedding on all qubits\n",
        "    - conv+pool on pairs (0,1),(2,3),(4,5),(6,7)\n",
        "    - conv+pool on pairs (0,2),(4,6)\n",
        "    - measure qubits 0 and 4\n",
        "    \"\"\"\n",
        "    qml.AngleEmbedding(inputs, wires=range(n_qubits), rotation=\"Y\")\n",
        "\n",
        "    w = weights.reshape(-1)\n",
        "    idx = 0\n",
        "\n",
        "    conv1 = [(0, 1), (2, 3), (4, 5), (6, 7)]\n",
        "    for p in conv1:\n",
        "        conv_block(w[idx:idx+3], p)\n",
        "        idx += 3\n",
        "\n",
        "    for p in conv1:\n",
        "        pooling_block(w[idx:idx+2], p)\n",
        "        idx += 2\n",
        "\n",
        "    conv2 = [(0, 2), (4, 6)]\n",
        "    for p in conv2:\n",
        "        conv_block(w[idx:idx+3], p)\n",
        "        idx += 3\n",
        "\n",
        "    for p in conv2:\n",
        "        pooling_block(w[idx:idx+2], p)\n",
        "        idx += 2\n",
        "\n",
        "    return [qml.expval(qml.PauliZ(0)), qml.expval(qml.PauliZ(4))]\n",
        "\n",
        "# conv1: 4×3 = 12, pool1: 4×2 = 8, conv2: 2×3 = 6, pool2: 2×2 = 4 => 30 params\n",
        "qcnn_shapes = {\"weights\": (30,)}\n",
        "QCNNLayer = qml.qnn.TorchLayer(qcnn_circuit, qcnn_shapes)"
      ],
      "metadata": {
        "id": "FLIGG2w7cbxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 6. Models: QNN, QCNN, HQNN\n",
        "# ----------------------------\n",
        "class QNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    QNN:\n",
        "    bitstring (784) -> SimpleDownscale -> QNNLayer -> Linear -> 10 logits\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre = SimpleDownscale(n_qubits)\n",
        "        self.q = QNNLayer\n",
        "        self.fc = nn.Linear(n_qubits, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre(x)        # -> (B,n_qubits)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.q(x)          # -> (B,n_qubits) (<Z>)\n",
        "        return self.fc(x)      # -> (B,10)\n",
        "\n",
        "\n",
        "class QCNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    QCNN:\n",
        "    bitstring (784) -> SimpleDownscale -> QCNNLayer -> Linear(2->10)\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.pre = SimpleDownscale(n_qubits)\n",
        "        self.q = QCNNLayer\n",
        "        self.fc = nn.Linear(2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pre(x)        # -> (B,n_qubits)\n",
        "        x = torch.tanh(x)\n",
        "        x = self.q(x)          # -> (B,2)\n",
        "        return self.fc(x)      # -> (B,10)\n",
        "\n",
        "\n",
        "class HQNNModel(nn.Module):\n",
        "    \"\"\"\n",
        "    HQNN (hybrid):\n",
        "    bitstring (784) -> SmallCNN -> Linear(latent->n_qubits)\n",
        "                      -> QNNLayer -> Linear -> 10 logits\n",
        "    \"\"\"\n",
        "    def __init__(self, latent_dim=32):\n",
        "        super().__init__()\n",
        "        self.cnn = SmallCNN(latent_dim)\n",
        "        self.to_q = nn.Linear(latent_dim, n_qubits)\n",
        "        self.q = QNNLayer\n",
        "        self.fc = nn.Linear(n_qubits, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        z = self.cnn(x)        # -> (B, latent_dim)\n",
        "        z = self.to_q(z)       # -> (B, n_qubits)\n",
        "        z = torch.tanh(z)\n",
        "        z = self.q(z)          # -> (B, n_qubits)\n",
        "        return self.fc(z)      # -> (B,10)"
      ],
      "metadata": {
        "id": "sOwrFYs5crO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 7. Plotting metrics\n",
        "# ----------------------------\n",
        "def plot_metrics(history, model_name):\n",
        "    \"\"\"\n",
        "    Plot train/test loss and accuracy over epochs.\n",
        "    Saves as <model_name>_metrics.png.\n",
        "    \"\"\"\n",
        "    epochs_list = history[\"epoch\"]\n",
        "    train_loss = history[\"train_loss\"]\n",
        "    test_loss  = history[\"test_loss\"]\n",
        "    train_acc  = history[\"train_acc\"]\n",
        "    test_acc   = history[\"test_acc\"]\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
        "\n",
        "    axs[0].plot(epochs_list, train_loss, label=\"Train loss\")\n",
        "    axs[0].plot(epochs_list, test_loss,  label=\"Test loss\")\n",
        "    axs[0].set_xlabel(\"Epoch\")\n",
        "    axs[0].set_ylabel(\"Loss\")\n",
        "    axs[0].set_title(\"Loss\")\n",
        "    axs[0].legend()\n",
        "\n",
        "    axs[1].plot(epochs_list, train_acc, label=\"Train acc\")\n",
        "    axs[1].plot(epochs_list, test_acc,  label=\"Test acc\")\n",
        "    axs[1].set_xlabel(\"Epoch\")\n",
        "    axs[1].set_ylabel(\"Accuracy\")\n",
        "    axs[1].set_title(\"Accuracy\")\n",
        "    axs[1].legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    out_name = f\"{model_name}_metrics.png\"\n",
        "    plt.savefig(out_name, dpi=300, bbox_inches=\"tight\")\n",
        "    print(f\"Saved metrics plot to {out_name}\")\n",
        "    plt.close(fig)"
      ],
      "metadata": {
        "id": "Ze84zsFxcyt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 8. Circuit figures (gate diagrams)\n",
        "# ----------------------------\n",
        "def save_circuit_figures():\n",
        "    \"\"\"\n",
        "    Draw and save circuit diagrams for QNN and QCNN using qml.draw_mpl.\n",
        "    Files:\n",
        "    - qnn_circuit.png\n",
        "    - qcnn_circuit.png\n",
        "    \"\"\"\n",
        "    # QNN\n",
        "    features_qnn = torch.zeros(n_qubits)\n",
        "    weights_qnn  = torch.zeros(n_layers, n_qubits, 3)\n",
        "    fig1, ax1 = qml.draw_mpl(qnn_circuit)(features_qnn, weights_qnn)\n",
        "    fig1.savefig(\"qnn_circuit.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"Saved QNN circuit figure to qnn_circuit.png\")\n",
        "    plt.close(fig1)\n",
        "\n",
        "    # QCNN\n",
        "    features_qcnn = torch.zeros(n_qubits)\n",
        "    weights_qcnn  = torch.zeros(30)\n",
        "    fig2, ax2 = qml.draw_mpl(qcnn_circuit)(features_qcnn, weights_qcnn)\n",
        "    fig2.savefig(\"qcnn_circuit.png\", dpi=300, bbox_inches=\"tight\")\n",
        "    print(\"Saved QCNN circuit figure to qcnn_circuit.png\")\n",
        "    plt.close(fig2)"
      ],
      "metadata": {
        "id": "P5i1h_9ec23n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 9. Training / evaluation with logging\n",
        "# ----------------------------\n",
        "def train_and_evaluate(model, model_name):\n",
        "    model = model.to(device)\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    history = {\n",
        "        \"epoch\": [],\n",
        "        \"train_loss\": [],\n",
        "        \"train_acc\": [],\n",
        "        \"test_loss\": [],\n",
        "        \"test_acc\": [],\n",
        "    }\n",
        "\n",
        "    for ep in range(1, epochs + 1):\n",
        "        # ---- train ----\n",
        "        model.train()\n",
        "        total_loss = 0.0\n",
        "        total_correct = 0\n",
        "        total_samples = 0\n",
        "\n",
        "        for xb, yb in train_loader:\n",
        "            xb, yb = xb.to(device), yb.to(device)\n",
        "            opt.zero_grad()\n",
        "            logits = model(xb)\n",
        "            loss = loss_fn(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "\n",
        "            total_loss += loss.item() * xb.size(0)\n",
        "            preds = logits.argmax(1)\n",
        "            total_correct += (preds == yb).sum().item()\n",
        "            total_samples += yb.size(0)\n",
        "\n",
        "        train_loss = total_loss / total_samples\n",
        "        train_acc = total_correct / total_samples\n",
        "\n",
        "        # ---- test ----\n",
        "        model.eval()\n",
        "        test_loss_total = 0.0\n",
        "        test_correct = 0\n",
        "        test_samples = 0\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in test_loader:\n",
        "                xb, yb = xb.to(device), yb.to(device)\n",
        "                logits = model(xb)\n",
        "                loss = loss_fn(logits, yb)\n",
        "                test_loss_total += loss.item() * xb.size(0)\n",
        "                preds = logits.argmax(1)\n",
        "                test_correct += (preds == yb).sum().item()\n",
        "                test_samples += yb.size(0)\n",
        "\n",
        "        test_loss = test_loss_total / test_samples\n",
        "        test_acc = test_correct / test_samples\n",
        "\n",
        "        history[\"epoch\"].append(ep)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"test_loss\"].append(test_loss)\n",
        "        history[\"test_acc\"].append(test_acc)\n",
        "\n",
        "        print(\n",
        "            f\"Epoch {ep:02d} | \"\n",
        "            f\"Train loss: {train_loss:.4f}, acc: {train_acc:.4f} | \"\n",
        "            f\"Test loss: {test_loss:.4f}, acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "    plot_metrics(history, model_name)\n",
        "    return history"
      ],
      "metadata": {
        "id": "fC9BJkS2c65q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# 10. Main\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    print(f\"Using device: {device}\")\n",
        "    print(f\"Training model: {MODEL_CHOICE.upper()} on binarized MNIST\")\n",
        "\n",
        "    if MODEL_CHOICE.lower() == \"qnn\":\n",
        "        model = QNNModel()\n",
        "        name = \"qnn\"\n",
        "    elif MODEL_CHOICE.lower() == \"qcnn\":\n",
        "        model = QCNNModel()\n",
        "        name = \"qcnn\"\n",
        "    elif MODEL_CHOICE.lower() == \"hqnn\":\n",
        "        model = HQNNModel()\n",
        "        name = \"hqnn\"\n",
        "    else:\n",
        "        raise ValueError(\"MODEL_CHOICE must be 'qnn', 'qcnn', or 'hqnn'.\")\n",
        "\n",
        "    history = train_and_evaluate(model, name)\n",
        "    save_circuit_figures()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ot5cQeS_c31E",
        "outputId": "b7fd80a9-7b81-428d-a8ce-af67dd76cc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Training model: HQNN on binarized MNIST\n",
            "Epoch 01 | Train loss: 1.9465, acc: 0.3739 | Test loss: 1.4079, acc: 0.7233\n",
            "Epoch 02 | Train loss: 0.9967, acc: 0.7629 | Test loss: 0.7571, acc: 0.7775\n",
            "Epoch 03 | Train loss: 0.6679, acc: 0.7857 | Test loss: 0.5980, acc: 0.7857\n",
            "Epoch 04 | Train loss: 0.5487, acc: 0.8075 | Test loss: 0.5106, acc: 0.8377\n",
            "Epoch 05 | Train loss: 0.4395, acc: 0.8739 | Test loss: 0.4247, acc: 0.8695\n",
            "Epoch 06 | Train loss: 0.3575, acc: 0.8839 | Test loss: 0.3522, acc: 0.8789\n",
            "Epoch 07 | Train loss: 0.3112, acc: 0.8908 | Test loss: 0.3206, acc: 0.8805\n",
            "Epoch 08 | Train loss: 0.2662, acc: 0.9354 | Test loss: 0.2648, acc: 0.9661\n",
            "Epoch 09 | Train loss: 0.2009, acc: 0.9748 | Test loss: 0.2043, acc: 0.9691\n",
            "Epoch 10 | Train loss: 0.1481, acc: 0.9783 | Test loss: 0.1820, acc: 0.9664\n",
            "Epoch 11 | Train loss: 0.1227, acc: 0.9794 | Test loss: 0.1518, acc: 0.9732\n",
            "Epoch 12 | Train loss: 0.1031, acc: 0.9825 | Test loss: 0.1518, acc: 0.9690\n",
            "Epoch 13 | Train loss: 0.0901, acc: 0.9835 | Test loss: 0.1384, acc: 0.9716\n",
            "Epoch 14 | Train loss: 0.0779, acc: 0.9857 | Test loss: 0.1414, acc: 0.9700\n",
            "Epoch 15 | Train loss: 0.0717, acc: 0.9865 | Test loss: 0.1370, acc: 0.9704\n",
            "Epoch 16 | Train loss: 0.0637, acc: 0.9878 | Test loss: 0.1293, acc: 0.9730\n",
            "Epoch 17 | Train loss: 0.0575, acc: 0.9885 | Test loss: 0.1410, acc: 0.9700\n",
            "Epoch 18 | Train loss: 0.0530, acc: 0.9894 | Test loss: 0.1307, acc: 0.9726\n",
            "Epoch 19 | Train loss: 0.0497, acc: 0.9899 | Test loss: 0.1265, acc: 0.9733\n",
            "Epoch 20 | Train loss: 0.0435, acc: 0.9916 | Test loss: 0.1281, acc: 0.9723\n",
            "Saved metrics plot to hqnn_metrics.png\n",
            "Saved QNN circuit figure to qnn_circuit.png\n",
            "Saved QCNN circuit figure to qcnn_circuit.png\n"
          ]
        }
      ]
    }
  ]
}